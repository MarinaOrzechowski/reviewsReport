{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REVIEWS SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, StaleElementReferenceException, ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time, requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape TrustPilot \n",
    "\n",
    "~23 pages. Need to scrape a page, and move to the next one. Repeat until reach last page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToDict(text):\n",
    "    parts = text.split('\",\"')\n",
    "    vocab = {}\n",
    "    \n",
    "    for i in range(len(parts)):\n",
    "        parts[i] = parts[i].replace('\\n{\"', '')\n",
    "        parts[i] = parts[i].replace('}\\n', '')\n",
    "        pair = parts[i].split('\":')\n",
    "        pair[0] = pair[0].replace('\"', '')\n",
    "        pair[1] = pair[1].replace('\"', '')\n",
    "        vocab[pair[0]] = pair[1]\n",
    "    return vocab\n",
    "\n",
    "df = pd.DataFrame(columns=('name', 'date', 'stars', 'text', 'boaDate', 'boaText', 'source'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\mskac\\.wdm\\drivers\\geckodriver\\win64\\v0.28.0\\geckodriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Opened page 2\n",
      ".........Opened page 3\n",
      ".........Opened page 4\n",
      ".........Opened page 5\n",
      ".........Opened page 6\n",
      ".........Opened page 7\n",
      ".........Opened page 8\n",
      ".........Opened page 9\n",
      ".........Opened page 10\n",
      ".........Opened page 11\n",
      ".........Opened page 12\n",
      ".........Opened page 13\n",
      ".........Opened page 14\n",
      ".........Opened page 15\n",
      ".........Opened page 16\n",
      ".........Opened page 17\n",
      ".........Opened page 18\n",
      ".........Opened page 19\n",
      ".........Opened page 20\n",
      ".........Opened page 21\n",
      ".........Opened page 22\n",
      ".........Opened page 23\n",
      "No more pages left\n",
      "processed all pages\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "url = 'https://www.trustpilot.com/review/www.bankofamerica.com'\n",
    "\n",
    "temp = 2\n",
    "driver.implicitly_wait(5)\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "xpath1 = '/html/body/div[4]/div[3]/div/div/div[3]/button'\n",
    "xpath2 = '/html/body/div[3]/a'\n",
    "# close accept cookies tab\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "# close Covid notification tab\n",
    "try:\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath2))).click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath1))).click()\n",
    "except TimeoutException:\n",
    "    pass\n",
    "\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "# close Covid notification tab\n",
    "try:\n",
    "    WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath2))).click()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "\n",
    "while True:   \n",
    "    try:\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "        for block in soup.find_all(\"article\", class_='review'):\n",
    "            # name, rating, review\n",
    "            script = block.find(\"script\").string\n",
    "            vocab = stringToDict(script)\n",
    "            name = vocab['consumerName']\n",
    "            stars = int(vocab['stars'])\n",
    "            text = vocab['reviewHeader']+vocab['reviewBody']\n",
    "\n",
    "            #date\n",
    "            dateBlock = block.find('div', class_='review-content-header__dates')\n",
    "            dateScript = dateBlock.find(\"script\").string\n",
    "            date = dateScript.split('\"')[3].split('T')[0]\n",
    "            y, m, d = date.split('-')\n",
    "            date = '/'.join([m, d, y])\n",
    "\n",
    "            df = df.append({'name' : name , 'date' : date, 'stars': stars, 'text': text, 'boaDate': None, 'boaText': None, 'source': 'trustpilot.com'} , ignore_index=True)        \n",
    "        \n",
    "        next_page_btn = driver.find_element_by_partial_link_text(\"Next page\")\n",
    "        # open next page\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Next page'))).click()\n",
    "        except  StaleElementReferenceException:\n",
    "            driver.implicitly_wait(5)\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Next page'))).click()\n",
    "        print('.........Opened page', temp)\n",
    "        temp += 1\n",
    "    except:\n",
    "        print(\"No more pages left\")\n",
    "        break\n",
    "print('processed all pages')        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/trustpilot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape BBB.com\n",
    "\n",
    "A single page, but needs 'load more' button to be pressed until scroll to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('name', 'date', 'stars', 'text', 'boaDate', 'boaText', 'source'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\mskac\\.wdm\\drivers\\geckodriver\\win64\\v0.28.0\\geckodriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      ".........Loaded more reviews\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "# press load more until reach end of the page\n",
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "url = 'https://www.bbb.org/us/nc/charlotte/profile/bank/bank-of-america-0473-100421/customer-reviews'\n",
    "driver.implicitly_wait(5)\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "xpath = '/html/body/div[2]/div[2]/div/button'\n",
    "css_selector = 'button.MuiButton-root:nth-child(2)'\n",
    "\n",
    "\n",
    "try:\n",
    "    # close cookies notification\n",
    "    myElem = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "    myElem.click()\n",
    "except TimeoutException:\n",
    "    pass\n",
    "driver.implicitly_wait(15)\n",
    "\n",
    "while True:   \n",
    "    try:   \n",
    "        # load more reviews\n",
    "        myElem = WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector)))\n",
    "        myElem.click()\n",
    "        print('.........Loaded more reviews')\n",
    "        sleep(5) # otherwise spinning circle blocks the button\n",
    "    except TimeoutException:\n",
    "        print(\"Done loading reviews\")\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for block in soup.find_all(\"div\", class_='MuiGrid-root styles__Review-sc-1azxajg-0 fyMiFZ dtm-review MuiGrid-container'):\n",
    "    stars = block.find_all(d='M259.3 17.8L194 150.2 47.9 171.5c-26.2 3.8-36.7 36.1-17.7 54.6l105.7 103-25 145.5c-4.5 26.3 23.2 46 46.4 33.7L288 439.6l130.7 68.7c23.2 12.2 50.9-7.4 46.4-33.7l-25-145.5 105.7-103c19-18.5 8.5-50.8-17.7-54.6L382 150.2 316.7 17.8c-11.7-23.6-45.6-23.9-57.4 0z')\n",
    "    stars = len(stars)\n",
    "    date = block.find(\"p\", class_='MuiTypography-root Typography-y2r0fa-0 kpIiVF MuiTypography-body2').text\n",
    "    name = block.find('p', class_='MuiTypography-root Name-t42m9k-0 kSwwPu MuiTypography-body2').text\n",
    "    text = block.find_all('div', class_='MuiTypography-root Text-sc-12c66pm-0 fgbKlJ MuiTypography-body2')\n",
    "    \n",
    "    if len(text)>1:\n",
    "        boaDate = block.find('p', class_='MuiTypography-root Date-sc-8slhbi-0 kEubpt MuiTypography-body1').text\n",
    "        boaText = text[1].text\n",
    "    else:\n",
    "        boaDate = None\n",
    "        boaText = None\n",
    "        \n",
    "    review = text[0].text\n",
    "    \n",
    "    df = df.append({'name' : name , 'date' : date, 'stars': stars, 'text': text, 'boaDate': boaDate, 'boaText': boaText, 'source': 'bbb.org'} , ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>boaDate</th>\n",
       "      <th>boaText</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scott o</td>\n",
       "      <td>11/21/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[[don't you set up an account with Bank of Ame...</td>\n",
       "      <td>11/27/2020</td>\n",
       "      <td>Thank you for sharing your experience. At Bank...</td>\n",
       "      <td>bbb.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samy  A</td>\n",
       "      <td>11/17/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Worst bank ever. I been a customer with Bank...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bbb.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharmell B</td>\n",
       "      <td>11/15/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Bank of America in McDonough ga 30253\\n\\nHas...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bbb.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pam M</td>\n",
       "      <td>11/12/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[[They have absolutely HORRIBE CUSTOMER SERVIC...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bbb.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gulshan G</td>\n",
       "      <td>11/04/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Have a checking account with direct deposit ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bbb.org</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name        date stars  \\\n",
       "0     scott o  11/21/2020     1   \n",
       "1     Samy  A  11/17/2020     1   \n",
       "2  Sharmell B  11/15/2020     1   \n",
       "3       Pam M  11/12/2020     1   \n",
       "4   Gulshan G  11/04/2020     1   \n",
       "\n",
       "                                                text     boaDate  \\\n",
       "0  [[don't you set up an account with Bank of Ame...  11/27/2020   \n",
       "1  [[Worst bank ever. I been a customer with Bank...        None   \n",
       "2  [[Bank of America in McDonough ga 30253\\n\\nHas...        None   \n",
       "3  [[They have absolutely HORRIBE CUSTOMER SERVIC...        None   \n",
       "4  [[Have a checking account with direct deposit ...        None   \n",
       "\n",
       "                                             boaText   source  \n",
       "0  Thank you for sharing your experience. At Bank...  bbb.org  \n",
       "1                                               None  bbb.org  \n",
       "2                                               None  bbb.org  \n",
       "3                                               None  bbb.org  \n",
       "4                                               None  bbb.org  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data\\bbb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape DepositAccounts.com\n",
    "\n",
    "1. Click 'View more'\n",
    "2. Find and click all 'Read More'\n",
    "3. Result: single page with reviews, so just scrape it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\mskac\\.wdm\\drivers\\geckodriver\\win64\\v0.28.0\\geckodriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "url = 'https://www.depositaccounts.com/banks/bank-of-america.html'\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "readMoreClassName = 'textExpand'\n",
    "\n",
    "# click 'View more'\n",
    "try:   \n",
    "    \n",
    "    viewMoreBtn = driver.find_element_by_partial_link_text(\"View MORE\")\n",
    "    viewMoreBtn.click()\n",
    "except TimeoutException:\n",
    "    print(\"Couldn't open all reviews page\")\n",
    "\n",
    "sleep(10)\n",
    "\n",
    "# expand all reviews\n",
    "more_buttons = driver.find_elements_by_class_name(readMoreClassName)\n",
    "for x in range(len(more_buttons)):\n",
    "    if more_buttons[x].is_displayed():\n",
    "        driver.execute_script(\"arguments[0].click();\", more_buttons[x])\n",
    "        time.sleep(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('name', 'date', 'stars', 'text', 'boaDate', 'boaText', 'source'))\n",
    "\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "starClassRe = re.compile('^stars')\n",
    "\n",
    "for block in soup.find_all(\"div\", class_='bankReviewContainer'):\n",
    "    title = block.find('h3').text\n",
    "    \n",
    "    stars = block.find('div', {\"class\" : starClassRe}).get('class')\n",
    "    stars = int(stars[1][-1])\n",
    "    \n",
    "    user = block.find('span', itemprop='author').text\n",
    "    date = block.find('span', itemprop='datePublished').get('datetime')\n",
    "    y, m, d = date.split('-')\n",
    "    date = '/'.join([m, d, y])\n",
    "    \n",
    "    text = block.find('p', itemprop='description').text\n",
    "    review = title+' '+text\n",
    "    \n",
    "    df = df.append({'name' : user , 'date' : date, 'stars': stars, \\\n",
    "                    'text': review, 'boaDate': None, 'boaText': None, 'source': 'depositaccounts.com'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data\\depositaccounts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape ConsumerAffairs.com\n",
    "\n",
    "1. Click read full review btn\n",
    "2. Process data\n",
    "3. Click Next btn\n",
    "4. Repeat 1-3 until no Next btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "url = 'https://www.consumeraffairs.com/finance/bofa.html'\n",
    "\n",
    "driver.implicitly_wait(5)\n",
    "driver.maximize_window()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=('name', 'date', 'stars', 'text', 'boaDate', 'boaText', 'source'))\n",
    "\n",
    "monthVocab = {'jan': 1, 'feb': 2, 'march':3 , 'april':4, 'may': 5, 'june':6, 'july':7 , 'aug':8, 'sept':9 ,'oct':10, 'nov': 11,'dec':12}\n",
    "page = 2\n",
    "\n",
    "while True:   \n",
    "    try:\n",
    "        #expend all reviews\n",
    "        more_buttons = driver.find_elements_by_partial_link_text('Read full review')\n",
    "        \n",
    "        for x in range(len(more_buttons)):\n",
    "            if more_buttons[x].is_displayed():\n",
    "                driver.execute_script(\"arguments[0].click();\", more_buttons[x])\n",
    "                time.sleep(1)\n",
    "        # process data on current page        \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "        for block in soup.find_all(\"div\", class_='rvw js-rvw'):\n",
    "            \n",
    "            stars = block.find('meta', itemprop = 'ratingValue').get('content')\n",
    "            stars = int(stars)\n",
    "            \n",
    "            user = block.find('strong', itemprop = 'author').text\n",
    "            user = user.split('of')[0]\n",
    "            \n",
    "            date = block.find('span', class_ = 'ca-txt-cpt').text.split(': ')[1]\n",
    "            date = date.replace('.', '').replace(',', '').lower()\n",
    "            m, d, y = date.split(' ')\n",
    "            m = str(monthVocab[m])\n",
    "            date = '/'.join([m.zfill(2), d.zfill(2), y])\n",
    "            \n",
    "            text = block.find('div', class_ = 'rvw-bd').find_all('p')[1].text\n",
    "\n",
    "            df = df.append({'name' : user.strip() , 'date' : date, 'stars': stars, 'text': text, 'boaDate': None, 'boaText': None, 'source': 'consumeraffairs.com'} , ignore_index=True)        \n",
    "        \n",
    "        next_page_btn = driver.find_element_by_partial_link_text(\"Next\")\n",
    "        # open next page\n",
    "        try:\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Next'))).click()\n",
    "        except  StaleElementReferenceException:\n",
    "            sleep(2)\n",
    "            WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.PARTIAL_LINK_TEXT, 'Next'))).click()\n",
    "        print('.........Opened next page', page)\n",
    "        page += 1\n",
    "    except:\n",
    "        print(\"No more pages left\")\n",
    "        break\n",
    "print('processed all pages')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>boaDate</th>\n",
       "      <th>boaText</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alicefournier</td>\n",
       "      <td>04/24/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>The Worst Experience I opened a bank account o...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RonF</td>\n",
       "      <td>03/19/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Bank Of America Is A RIPOFF Bank of America is...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sdubey</td>\n",
       "      <td>02/28/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT REFINANCE With BOA We were referred to ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Corry_El</td>\n",
       "      <td>01/09/2020</td>\n",
       "      <td>2</td>\n",
       "      <td>GOOD REWARDS, TERRIBLE INTEREST This is mainly...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mbpacific</td>\n",
       "      <td>11/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Bank Of America Online Billpay SUCKS On Septem...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JaneInVegas</td>\n",
       "      <td>07/04/2019</td>\n",
       "      <td>4</td>\n",
       "      <td>Good Bank, Terrible Interest On Basic Savings ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Damianjd1992</td>\n",
       "      <td>07/02/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Bank Of America Worst Bank Why would anyone wa...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Imaguil</td>\n",
       "      <td>06/28/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>BANK OF AMERICA CLOSED ACCOUNTS I never like b...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Joeb</td>\n",
       "      <td>05/23/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Wrongful Banking To Elderly People Bank of Ame...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unsatisfied11</td>\n",
       "      <td>05/19/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Restricted Card, Hung Up On Hold So, my chip g...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>webbte</td>\n",
       "      <td>04/17/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Hope You Like Fees My account had money in it ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mandybritt</td>\n",
       "      <td>04/07/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Awful Check Deposit Policy And Customer Servic...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MrDoug85132</td>\n",
       "      <td>02/03/2019</td>\n",
       "      <td>3</td>\n",
       "      <td>HSA Accounts Two years ago I went into my loca...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>activelori</td>\n",
       "      <td>01/01/2019</td>\n",
       "      <td>1</td>\n",
       "      <td>Leaving B Of A I find there service poor and t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ACustomerHilton</td>\n",
       "      <td>12/01/2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Hellish Nightmare. The Absolute Worst! First t...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>depositaccounts.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name        date stars  \\\n",
       "0      alicefournier  04/24/2020     1   \n",
       "1               RonF  03/19/2020     1   \n",
       "2             sdubey  02/28/2020     1   \n",
       "3           Corry_El  01/09/2020     2   \n",
       "4          Mbpacific  11/02/2019     1   \n",
       "5        JaneInVegas  07/04/2019     4   \n",
       "6       Damianjd1992  07/02/2019     1   \n",
       "7            Imaguil  06/28/2019     1   \n",
       "8               Joeb  05/23/2019     1   \n",
       "9      Unsatisfied11  05/19/2019     1   \n",
       "10            webbte  04/17/2019     1   \n",
       "11        Mandybritt  04/07/2019     1   \n",
       "12       MrDoug85132  02/03/2019     3   \n",
       "13        activelori  01/01/2019     1   \n",
       "14   ACustomerHilton  12/01/2018     1   \n",
       "\n",
       "                                                 text boaDate boaText  \\\n",
       "0   The Worst Experience I opened a bank account o...    None    None   \n",
       "1   Bank Of America Is A RIPOFF Bank of America is...    None    None   \n",
       "2   DO NOT REFINANCE With BOA We were referred to ...    None    None   \n",
       "3   GOOD REWARDS, TERRIBLE INTEREST This is mainly...    None    None   \n",
       "4   Bank Of America Online Billpay SUCKS On Septem...    None    None   \n",
       "5   Good Bank, Terrible Interest On Basic Savings ...    None    None   \n",
       "6   Bank Of America Worst Bank Why would anyone wa...    None    None   \n",
       "7   BANK OF AMERICA CLOSED ACCOUNTS I never like b...    None    None   \n",
       "8   Wrongful Banking To Elderly People Bank of Ame...    None    None   \n",
       "9   Restricted Card, Hung Up On Hold So, my chip g...    None    None   \n",
       "10  Hope You Like Fees My account had money in it ...    None    None   \n",
       "11  Awful Check Deposit Policy And Customer Servic...    None    None   \n",
       "12  HSA Accounts Two years ago I went into my loca...    None    None   \n",
       "13  Leaving B Of A I find there service poor and t...    None    None   \n",
       "14  Hellish Nightmare. The Absolute Worst! First t...    None    None   \n",
       "\n",
       "                 source  \n",
       "0   depositaccounts.com  \n",
       "1   depositaccounts.com  \n",
       "2   depositaccounts.com  \n",
       "3   depositaccounts.com  \n",
       "4   depositaccounts.com  \n",
       "5   depositaccounts.com  \n",
       "6   depositaccounts.com  \n",
       "7   depositaccounts.com  \n",
       "8   depositaccounts.com  \n",
       "9   depositaccounts.com  \n",
       "10  depositaccounts.com  \n",
       "11  depositaccounts.com  \n",
       "12  depositaccounts.com  \n",
       "13  depositaccounts.com  \n",
       "14  depositaccounts.com  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(r'data\\depositaccounts.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.source == 'consumeraffairs.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'data\\consumeraffairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
